# -*- coding: utf-8 -*-
"""Dataset Builder

Automatically generated by Colaboratory.

"""

!pip install git+git://github.com/hhursev/recipe-scrapers.git

from recipe_scrapers import scrape_me
from bs4 import BeautifulSoup
import requests
import json
import pandas as pd
import numpy as np

df = pd.read_csv('dataset-url-title.csv', encoding='ISO-8859-1')

def macroFinder(macro, soup):
    tag = soup.find('span', {'class': 'gz-list-macros-name'}, text=macro)

    if tag:
        value = tag.findNext().findNext().text
        unit = tag.findNext().text
    else:
        value = ''
        unit = ''
    return [value, unit]

def search(url):
    print (url)
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    # calories
    finder = macroFinder('Energia', soup)
    caloriesValue = finder[0]
    caloriesUnit = finder[1]
    
    # carbs
    finder = macroFinder('Carboidrati', soup)
    carbohydratesValue = finder[0]
    carbohydratesUnit = finder[1]
    
    # sugar
    finder = macroFinder('\xa0\xa0di cui zuccheri', soup)
    sugarsValue = finder[0]
    sugarsUnit = finder[1]

    # protein
    finder = macroFinder('Proteine', soup)
    proteinsValue = finder[0]
    proteinsUnit = finder[1] 

    # fat
    finder = macroFinder('Grassi', soup)
    fatsValue = finder[0]
    fatsUnit = finder[1]

    # saturatedFat
    finder = macroFinder('\xa0\xa0di cui saturi', soup)
    saturatedFatsValue = finder[0]
    saturatedFatsUnit = finder[1]

    # fiber
    finder = macroFinder('Fibre', soup)
    fibersValue = finder[0]
    fibersUnit = finder[1]

    # sodium
    finder = macroFinder('Sodio', soup)
    sodiumValue = finder[0]
    sodiumUnit = finder[1]

    # cholesterol
    finder = macroFinder('Colesterolo', soup)
    cholesterolValue = finder[0]
    cholesterolUnit = finder[1]

    # JSON data
    j = json.loads(soup.find('script', type='application/ld+json').text)

    # cost
    try:
        cost = j['estimatedCost']
    except KeyError as e:
        cost = ''

    # category
    try:
        category = j['recipeCategory']
    except KeyError as e:
        category = ''

    # image
    try:
        imageURL = j['image']
    except KeyError as e:
        imageURL = ''

    # description
    try:
        description = j['description']
    except KeyError as e:
        description = ''

    # prepTime
    try:
        prepTime = j['prepTime']
    except KeyError as e:
        prepTime = ''

    # cookTime
    try:
        cookTime = j['cookTime']
    except KeyError as e:
        cookTime = ''

    # totalTime
    try:
        totalTime = j['totalTime']
    except KeyError as e:
        totalTime = ''

    # yield
    try:
        yield_ = j['recipeYield']
    except KeyError as e:
        yield_ = ''

    scraper = scrape_me(url)

    # ingredients
    ingredients = scraper.ingredients()

    ingredientsHTML = soup.findAll("dd", {"class": "gz-ingredient"})
    bagOfIngredients = [ingredient.a.text for ingredient in ingredientsHTML]

    # instructions
    instructions = scraper.instructions()

    # best rating
    try:
        bestRating = j['aggregateRating']['bestRating']
    except KeyError as e:
        bestRating = ''

    # rating count
    try:
        ratingCount = j['aggregateRating']['ratingCount']
    except KeyError as e:
        ratingCount = ''

    # rating value
    try:
        ratingValue = j['aggregateRating']['ratingValue']
    except KeyError as e:
        ratingValue = ''
    # isVegetarian
    isVegetarian = 1 if soup.find('span', {'class': 'gz-icon gz-icon-benessere-vegetariane'}) else 0
    
    # isLowNickel
    isLowNickel = 1 if soup.find('span', {'class': 'gz-icon gz-icon-benessere-basso-nichel'}) else 0

    # isLight
    isLight = 1 if soup.find('span', {'class': 'gz-icon gz-icon-benessere-light'}) else 0

    # isGlutenFree
    isGlutenFree = 1 if soup.find('span', {'class': 'gz-icon gz-icon-benessere-senza-glutine'}) else 0
    
    # is lactose free
    isLactoseFree = 1 if soup.find('span', {'class': 'gz-icon gz-icon-benessere-senza-lattosio'}) else 0
    
    # difficulty
    #difficulty = soup.find('span')
    
    return pd.Series(dict(zip(['cost',
                               'category',
                               'imageURL',
                               'description',
                               'prepTime', 'cookTime', 'totalTime',
                               'yield',
                               'isVegetarian', 'isLactoseFree', 'isGlutenFree', 'isLight', 'isLowNickel',
                               'calories','caloriesUnit', 
                               'carbohydrates','carbohydratesUnit',
                               'sugars','sugarsUnit',
                               'proteins','proteinsUnit',
                               'fat', 'fatUnit', 
                               'saturatedFat', 'saturatedFatUnit',
                               'fibers', 'fibersUnit',
                               'cholesterol', 'cholesterolUnit',
                               'sodium', 'sodiumUnit',
                               'ingredients_measure',
                               'ingredients',
                               'instructions',
                               'bestRating', 'ratingCount', 'ratingValue'
                               ], 
                              [cost,
                               category,
                               imageURL,
                               description, 
                               prepTime, cookTime, totalTime,
                               yield_,
                               isVegetarian, isLactoseFree, isGlutenFree, isLight, isLowNickel,
                               caloriesValue, caloriesUnit, 
                               carbohydratesValue, carbohydratesUnit, 
                               sugarsValue, sugarsUnit, 
                               proteinsValue, proteinsUnit, 
                               fatsValue, fatsUnit, 
                               saturatedFatsValue, saturatedFatsUnit, 
                               fibersValue, fibersUnit, 
                               cholesterolValue, cholesterolUnit,
                               sodiumValue, sodiumUnit,
                               ingredients, 
                               bagOfIngredients, 
                               instructions,
                               bestRating, ratingCount, ratingValue
                               ])))


df = pd.concat([df, df.link.apply(search)], axis = 1)

df.to_csv('dataset.csv', index=False)